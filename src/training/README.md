# Scripts de MLFlow - Documentaci√≥n Completa

Este directorio contiene todos los scripts relacionados con MLFlow para el proyecto de ML de Chicago Crimes.

## üìã √çndice

1. [Resumen del Proyecto](#resumen-del-proyecto)
2. [Scripts Disponibles](#scripts-disponibles)
3. [Fases Completadas](#fases-completadas)
4. [Prerequisitos](#prerequisitos)
5. [Gu√≠a de Uso](#gu√≠a-de-uso)
6. [Resultados y M√©tricas](#resultados-y-m√©tricas)

---

## üìä Resumen del Proyecto

### Objetivo
Implementar un sistema completo de MLOps usando MLFlow para gestionar el ciclo de vida de modelos de Machine Learning para predicci√≥n de arrestos en cr√≠menes de Chicago.

### Problema de Negocio
**Clasificaci√≥n binaria**: Predecir si un crimen resultar√° en arresto (Arrest_tag: 0=No, 1=S√≠)
- Dataset desbalanceado (55% No Arrest, 45% Arrest)
- Dataset: 194,897 muestras de entrenamiento, 50,744 de test
- 7 features despu√©s de preprocesamiento

### Arquitectura MLFlow
- **PostgreSQL** (Puerto 5432): Metadatos
- **MinIO** (Puerto 9000/9001): Artefactos S3-compatible
- **MLFlow Server** (Puerto 5001): API + UI Web

---

## üìú Scripts Disponibles

### 1. verify_mlflow_setup.py
**Prop√≥sito**: Verificar la infraestructura y conectividad de MLFlow

**Descripci√≥n**: 
- Verifica la conexi√≥n al servidor MLFlow
- Valida la configuraci√≥n de MinIO (S3)
- Prueba la creaci√≥n de experimentos y runs
- Valida todas las librer√≠as Python requeridas

**Uso**:
```bash
python mlflow_scripts/verify_mlflow_setup.py
```

**Salida esperada**: Estado de conexi√≥n, versiones de librer√≠as, creaci√≥n de experimento de prueba

---

### 2. mlflow_xgboost_poc.py
**Prop√≥sito**: Prueba de Concepto - Modelo XGBoost con tracking de MLFlow

**Descripci√≥n**:
- Carga el dataset de Chicago Crimes (train/test)
- Entrena clasificador XGBoost
- Registra todos los par√°metros, m√©tricas y artefactos en MLFlow
- Crea visualizaciones (matriz de confusi√≥n, importancia de features)
- Registra el modelo en MLFlow Model Registry

**Uso**:
```bash
python mlflow_scripts/mlflow_xgboost_poc.py
```

**Salidas**:
- Experimento MLFlow: `chicago_crimes_xgboost`
- Modelo registrado: `xgboost_chicago_crimes`
- M√©tricas: Accuracy, Precision, Recall, F1, AUC, MCC
- Artefactos: Matriz de confusi√≥n, gr√°ficos de importancia de features, reporte de clasificaci√≥n

**Resultados** (Conjunto de Test):
- Accuracy: 90.81%
- MCC: 0.5624
- AUC: 87.90%
- Tiempo de entrenamiento: ~2 segundos

---

### 3. check_mlflow_model.py
**Prop√≥sito**: Verificar modelos registrados y runs recientes

**Descripci√≥n**:
- Lista todos los modelos registrados en MLFlow
- Muestra versiones y stages de modelos
- Despliega runs recientes en experimentos
- Ayuda a verificar el estado de registro de modelos

**Uso**:
```bash
python mlflow_scripts/check_mlflow_model.py
```

---

### 4. mlflow_training_helper.py
**Prop√≥sito**: Funciones helper reutilizables para entrenamiento con MLFlow

**Descripci√≥n**:
- M√≥dulo con funciones utilitarias para simplificar el tracking con MLFlow
- Configuraci√≥n autom√°tica del entorno MLFlow
- C√°lculo estandarizado de m√©tricas de clasificaci√≥n
- Creaci√≥n de visualizaciones (matriz de confusi√≥n, importancia de features)
- Funci√≥n principal `train_and_log_model()` que encapsula todo el flujo

**Funciones principales**:
- `setup_mlflow_environment()`: Configura variables de entorno
- `get_or_create_experiment()`: Obtiene o crea experimento
- `train_and_log_model()`: Entrena modelo y registra todo en MLFlow
- `calculate_classification_metrics()`: Calcula m√©tricas completas
- `create_confusion_matrix_plot()`: Genera matriz de confusi√≥n
- `create_feature_importance_plot()`: Genera gr√°fico de importancia
- `compare_models()`: Compara modelos de un experimento

**Uso**:
```python
from mlflow_training_helper import train_and_log_model

model, run_id, metrics = train_and_log_model(
    model=XGBClassifier(),
    X_train=X_train, y_train=y_train,
    X_test=X_test, y_test=y_test,
    experiment_name="my_experiment",
    run_name="xgboost_v1",
    model_name="my_model"
)
```

---

### 5. train_multiple_models.py
**Prop√≥sito**: Ejemplo de entrenamiento de m√∫ltiples modelos usando helpers

**Descripci√≥n**:
- Demuestra el uso de `mlflow_training_helper`
- Entrena 5 modelos diferentes:
  - Logistic Regression
  - Decision Tree
  - Random Forest
  - AdaBoost
  - XGBoost
- Compara resultados autom√°ticamente
- Registra todos los modelos en MLFlow

**Uso**:
```bash
python mlflow_scripts/train_multiple_models.py
```

**Salidas**:
- Experimento MLFlow: `chicago_crimes_all_models`
- 5 modelos registrados con sus m√©tricas
- Comparaci√≥n autom√°tica por MCC score

---

### 6. train_all_8_models.py ‚≠ê
**Prop√≥sito**: Migraci√≥n completa de los 8 modelos originales a MLFlow

**Descripci√≥n**:
- Replica la implementaci√≥n original de `modelos/machine_learning.ipynb`
- Entrena los 8 modelos con configuraciones id√©nticas:
  1. Logistic Regression
  2. K-Nearest Neighbors (k=10)
  3. SVM Linear
  4. Decision Tree
  5. Random Forest (20 estimators)
  6. Bagging (Logistic Regression, 20 estimators)
  7. AdaBoost (max_depth=5, 20 estimators)
  8. XGBoost (100 estimators)
- Compara todos los modelos por MCC
- Valida resultados contra m√©tricas originales

**Uso**:
```bash
python mlflow_scripts/train_all_8_models.py
```

**Salidas**:
- Experimento MLFlow: `chicago_crimes_8_models`
- 8 modelos registrados en Model Registry
- Tabla comparativa completa
- Ranking por MCC score

**Resultados**:
- ‚úÖ XGBoost: MCC 0.5624 (Mejor modelo)
- ‚úÖ Random Forest: MCC 0.5230
- ‚úÖ AdaBoost: MCC 0.4999
- Tiempo total: ~2 minutos

### 7. champion_challenger.py
**Prop√≥sito**: Sistema de gesti√≥n Champion/Challenger para Model Registry

**Descripci√≥n**:
- Clase `ChampionChallengerManager` para gesti√≥n completa del ciclo de vida
- Asignaci√≥n y gesti√≥n de aliases (champion, challenger, previous_champion)
- Comparaci√≥n autom√°tica de modelos (m√©tricas almacenadas y evaluaci√≥n en vivo)
- Promoci√≥n autom√°tica con backup del champion anterior
- Capacidad de rollback a versi√≥n anterior
- Soporte para A/B testing

**Funciones principales**:
- `set_alias()` / `delete_alias()`: Gesti√≥n de aliases
- `compare_models()`: Comparaci√≥n completa entre champion y challenger
- `promote_challenger()`: Promoci√≥n segura con backup
- `rollback_champion()`: Revertir a champion anterior
- `get_model_versions()`: Ver historial de versiones

**Uso**:
```python
from champion_challenger import ChampionChallengerManager

manager = ChampionChallengerManager()
manager.set_alias("xgboost_chicago", "champion", "1")
manager.set_alias("random_forest_chicago", "challenger", "1")

comparison = manager.compare_models(
    champion_model_name="xgboost_chicago",
    challenger_model_name="random_forest_chicago"
)
```

---

### 8. demo_champion_challenger.py
**Prop√≥sito**: Demostraci√≥n completa del workflow Champion/Challenger

**Descripci√≥n**:
- Workflow completo de 6 pasos
- Setup inicial de champion y challenger
- Comparaci√≥n con m√©tricas almacenadas
- Evaluaci√≥n en vivo con datos de test
- Decisi√≥n autom√°tica de promoci√≥n (threshold configurable)
- Demostraci√≥n de rollback
- Evaluaci√≥n de m√∫ltiples challengers

**Uso**:
```bash
python mlflow_scripts/demo_champion_challenger.py
```

**Salidas**:
- Comparaci√≥n detallada de m√©tricas
- Recomendaci√≥n de promoci√≥n
- Tabla de resultados en vivo
- Decisi√≥n basada en threshold (default: 1% mejora en MCC)

---

## üéØ Fases Completadas

### ‚úÖ Fase 1: Infraestructura MLFlow (Docker)
**Objetivo**: Configurar y verificar infraestructura Docker de MLFlow

**Logros**:
- Docker Compose con PostgreSQL, MinIO y MLFlow Server
- Configuraci√≥n de vol√∫menes persistentes
- Healthchecks para todos los servicios
- Documentaci√≥n de inicio y troubleshooting

**Archivos**: `../mlflow_system/docker-compose.yml`, `Dockerfile`, `requirements.txt`

**Verificaci√≥n**: 
- MLFlow UI: http://localhost:5001 ‚úì
- MinIO Console: http://localhost:9001 ‚úì
- PostgreSQL: localhost:5432 ‚úì

---

### ‚úÖ Fase 2: POC XGBoost con MLFlow
**Objetivo**: Crear prueba de concepto con modelo XGBoost

**Logros**:
- Script completo de entrenamiento con tracking
- Logging de par√°metros, m√©tricas y artefactos
- Visualizaciones (confusion matrix, feature importance)
- Registro en Model Registry
- Manejo de compatibilidad Windows/MLFlow

**Resultados**:
- Test Accuracy: 90.81%
- Test MCC: 0.5624 (mejor m√©trica para datos desbalanceados)
- Test AUC: 87.90%
- Tiempo de entrenamiento: ~2 segundos

**Archivo**: `mlflow_xgboost_poc.py`

---

### ‚úÖ Fase 3: Funciones Helper Reutilizables
**Objetivo**: Crear m√≥dulo de funciones helper para simplificar el tracking

**Logros**:
- M√≥dulo `mlflow_training_helper.py` con 7 funciones principales
- Funci√≥n `train_and_log_model()` que automatiza todo el flujo
- Reducci√≥n de ~93% de c√≥digo repetitivo
- Soporte para cualquier modelo compatible con scikit-learn
- C√°lculo autom√°tico de m√©tricas completas
- Generaci√≥n autom√°tica de visualizaciones

**Funciones implementadas**:
1. `setup_mlflow_environment()` - Configuraci√≥n autom√°tica
2. `get_or_create_experiment()` - Gesti√≥n de experimentos
3. `calculate_classification_metrics()` - M√©tricas completas
4. `create_confusion_matrix_plot()` - Visualizaci√≥n
5. `create_feature_importance_plot()` - Visualizaci√≥n
6. `train_and_log_model()` - Funci√≥n principal ‚≠ê
7. `compare_models()` - Comparaci√≥n de modelos

**Archivo**: `mlflow_training_helper.py`

---

### ‚úÖ Fase 4: Migraci√≥n de 8 Modelos
**Objetivo**: Migrar todos los modelos originales a MLFlow

**Logros**:
- 8/8 modelos migrados exitosamente
- Configuraciones id√©nticas a implementaci√≥n original
- Validaci√≥n de resultados contra m√©tricas originales
- Todos los modelos registrados en Model Registry
- Comparaci√≥n autom√°tica por MCC

**Modelos migrados**:
1. Logistic Regression - MCC: 0.2127
2. K-Nearest Neighbors (k=10) - MCC: 0.1706
3. SVM Linear - MCC: 0.2149
4. Decision Tree - MCC: 0.4192
5. Random Forest (20 est.) - MCC: 0.5230
6. Bagging (LR, 20 est.) - MCC: 0.2128
7. AdaBoost (20 est.) - MCC: 0.4999
8. XGBoost (100 est.) - MCC: 0.5624 ‚≠ê **CHAMPION**

**Experimento**: `chicago_crimes_8_models`
**Archivo**: `train_all_8_models.py`

---

### ‚úÖ Fase 5: Sistema Champion/Challenger
**Objetivo**: Implementar patr√≥n Champion/Challenger para gesti√≥n de modelos

**Logros**:
- Clase `ChampionChallengerManager` completa
- Sistema de aliases (champion, challenger, previous_champion)
- Comparaci√≥n autom√°tica de modelos
- Promoci√≥n segura con backup
- Rollback en un comando
- Evaluaci√≥n en vivo con datos de test
- Soporte para m√∫ltiples challengers
- Decisi√≥n autom√°tica basada en threshold

**Caracter√≠sticas**:
- Comparaci√≥n usando m√©tricas almacenadas
- Evaluaci√≥n en vivo cargando modelos desde artifacts
- Tabla comparativa autom√°tica
- Threshold configurable (default: 1% mejora)
- Backup autom√°tico del champion actual
- Capacidad de rollback completa

**Archivos**: `champion_challenger.py`, `demo_champion_challenger.py`

---

## üìã Prerequisitos

1. **Infraestructura Docker de MLFlow en ejecuci√≥n**:
   ```bash
   cd mlflow_system
   docker compose up -d
   ```

2. **Entorno virtual activado**:
   ```bash
   .\.venv\Scripts\activate
   ```

3. **Acceso a MLFlow UI**: http://localhost:5001

## Variables de Entorno

Todos los scripts configuran autom√°ticamente:
- `AWS_ACCESS_KEY_ID=minio`
- `AWS_SECRET_ACCESS_KEY=minio123`
- `MLFLOW_S3_ENDPOINT_URL=http://localhost:9000`
- `MLFLOW_TRACKING_URI=http://localhost:5001`

## üìö Gu√≠a de Uso

### Inicio R√°pido

1. **Iniciar infraestructura MLFlow**:
```bash
cd mlflow_system
docker compose up -d
```

2. **Verificar instalaci√≥n**:
```bash
.\.venv\Scripts\activate
python mlflow_scripts/verify_mlflow_setup.py
```

3. **Entrenar todos los modelos**:
```bash
python mlflow_scripts/train_all_8_models.py
```

4. **Configurar Champion/Challenger**:
```bash
python mlflow_scripts/demo_champion_challenger.py
```

### Workflows Comunes

#### Entrenar un modelo individual
```python
from mlflow_training_helper import train_and_log_model
from sklearn.ensemble import RandomForestClassifier

model, run_id, metrics = train_and_log_model(
    model=RandomForestClassifier(n_estimators=100),
    X_train=X_train, y_train=y_train,
    X_test=X_test, y_test=y_test,
    experiment_name="my_experiment",
    run_name="rf_v1",
    model_name="my_rf_model"
)
```

#### Comparar modelos
```python
from champion_challenger import ChampionChallengerManager

manager = ChampionChallengerManager()
comparison = manager.compare_models(
    champion_model_name="xgboost_chicago",
    challenger_model_name="random_forest_chicago",
    X_test=X_test,
    y_test=y_test
)
```

#### Promover un modelo
```python
# Si el challenger supera al champion
manager.promote_challenger(
    model_name="xgboost_chicago",
    champion_alias="champion",
    challenger_alias="challenger"
)
```

---

## üìä Resultados y M√©tricas

### Ranking Final de Modelos (por MCC)

| Posici√≥n | Modelo | Test MCC | Test Accuracy | Test AUC | Tiempo (s) | Estado |
|----------|--------|----------|---------------|----------|------------|--------|
| ü•á 1 | **XGBoost** | **0.5624** | **90.81%** | **87.90%** | 2.83 | **CHAMPION** |
| ü•à 2 | Random Forest | 0.5230 | 89.49% | 85.47% | 6.70 | Challenger |
| ü•â 3 | AdaBoost | 0.4999 | 89.04% | 86.26% | 31.00 | - |
| 4 | Decision Tree | 0.4192 | 84.48% | 73.77% | 5.34 | - |
| 5 | SVM Linear | 0.2149 | 65.90% | N/A | 0.32 | - |
| 6 | Bagging (LR) | 0.2128 | 66.43% | 67.21% | 23.33 | - |
| 7 | Logistic Regression | 0.2127 | 66.41% | 67.21% | 13.25 | - |
| 8 | KNN (k=10) | 0.1706 | 75.88% | 64.38% | 1.27 | - |

### Comparaci√≥n Champion vs Challenger

**XGBoost (Champion)** vs **Random Forest (Challenger)**:

| M√©trica | Champion | Challenger | Diferencia | Ganador |
|---------|----------|------------|------------|---------|
| MCC | 0.5624 | 0.5230 | -0.0394 | Champion |
| Accuracy | 90.81% | 89.49% | -1.32% | Champion |
| AUC | 87.90% | 85.47% | -2.43% | Champion |
| F1-Score | 89.99% | 89.04% | -0.95% | Champion |

**Decisi√≥n**: Mantener XGBoost como champion ‚úì

### M√©tricas Clave del Champion (XGBoost)

- **MCC**: 0.5624 (m√©trica m√°s robusta para datos desbalanceados)
- **Accuracy**: 90.81%
- **Precision**: 90.00%
- **Recall**: 90.81%
- **F1-Score**: 89.99%
- **AUC**: 87.90%
- **Tiempo de entrenamiento**: 2.83s
- **Tiempo de predicci√≥n**: 0.90s

### Estad√≠sticas del Proyecto

- **Total de modelos entrenados**: 8
- **Modelos registrados en MLFlow**: 8
- **Experimentos creados**: 3
  - `test_verification` - Verificaci√≥n inicial
  - `chicago_crimes_xgboost` - POC XGBoost
  - `chicago_crimes_8_models` - Todos los modelos
- **Total de runs**: 10+
- **Artefactos generados**: 24+ (matrices de confusi√≥n, feature importance, reports)

---

## üîó Enlaces √ötiles

- **MLFlow UI**: http://localhost:5001
- **MinIO Console**: http://localhost:9001 (user: minio, pass: minio123)
- **Documentaci√≥n MLFlow**: https://mlflow.org/docs/latest/index.html
- **Repositorio del proyecto**: (agregar URL si aplica)

---

## üìù Notas Importantes

1. **C√≥digo en Ingl√©s**: Todo el c√≥digo y comentarios est√°n en ingl√©s siguiendo las mejores pr√°cticas
2. **Documentaci√≥n en Espa√±ol**: Los archivos .md est√°n en espa√±ol para facilitar la comprensi√≥n
3. **Compatibilidad Windows**: Todos los scripts manejan correctamente encoding Unicode
4. **Versionado**: Todos los modelos est√°n versionados en MLFlow Model Registry
5. **Reproducibilidad**: Todos los experimentos incluyen seeds aleatorios fijos (random_state=42)

---

### 9. predictor.py ‚≠ê
**Prop√≥sito**: Clase de producci√≥n para deployment de modelos

**Descripci√≥n**:
- Clase `ChicagoCrimePredictor` lista para producci√≥n
- Carga modelos por alias desde MLFlow Model Registry
- Validaci√≥n autom√°tica de features de entrada
- Soporte para predicciones individuales y por lotes
- Explicaciones detalladas de predicciones
- Logging opcional de predicciones a MLFlow
- Manejo robusto de errores

**Funciones principales**:
- `__init__()`: Inicializa predictor cargando modelo por alias
- `predict()`: Predicci√≥n con validaci√≥n
- `predict_proba()`: Probabilidades de clase positiva
- `predict_with_explanation()`: Predicci√≥n con explicaci√≥n detallada
- `get_model_info()`: Metadata completa del modelo
- `batch_predict()`: Predicciones por lotes para datasets grandes
- `log_prediction()`: Logging de predicciones para monitoreo

**Uso**:
```python
from predictor import ChicagoCrimePredictor

# Initialize with champion model
predictor = ChicagoCrimePredictor(
    model_name="xgboost_chicago",
    alias="champion"
)

# Make prediction
prediction = predictor.predict(crime_features)
probability = predictor.predict_proba(crime_features)

# Get detailed explanation
explanation = predictor.predict_with_explanation(crime_features)
```

**Caracter√≠sticas**:
- Detecci√≥n autom√°tica de features desde el modelo
- Validaci√≥n de entrada (features faltantes, valores nulos)
- Soporte para dict, DataFrame y list de dicts
- Batch processing con progress tracking
- Feature importance en explicaciones
- Compatible con cualquier modelo scikit-learn

---

### 10. demo_predictor.py
**Prop√≥sito**: Demostraci√≥n completa del predictor en producci√≥n

**Descripci√≥n**:
- 8 demos diferentes mostrando todas las funcionalidades
- Carga y uso del champion model
- Predicciones individuales y por lotes
- Comparaci√≥n champion vs challenger
- Validaci√≥n y manejo de errores
- Evaluaci√≥n en datos reales

**Uso**:
```bash
python mlflow_scripts/demo_predictor.py
```

**Demos incluidos**:
1. Inicializaci√≥n del predictor
2. Informaci√≥n del modelo
3. Predicci√≥n individual (dict input)
4. Predicci√≥n con explicaci√≥n
5. Predicciones m√∫ltiples (DataFrame)
6. Batch prediction en test data
7. Comparaci√≥n champion vs challenger
8. Validaci√≥n y manejo de errores

**Resultados**:
- Batch Accuracy: 90.40% en 1,000 muestras
- Agreement champion/challenger: 95.30%
- Todas las validaciones funcionando correctamente

---

## üéâ Proyecto Completado (6/6 Fases)

**Estado**: ‚úÖ TODAS LAS FASES COMPLETADAS (100%)

### Resumen de Logros:
- ‚úÖ Infraestructura MLFlow operativa
- ‚úÖ 8 modelos migrados y versionados
- ‚úÖ Sistema Champion/Challenger funcional
- ‚úÖ Clase Predictor lista para producci√≥n
- ‚úÖ Documentaci√≥n completa y unificada
- ‚úÖ 10 scripts Python funcionales
- ‚úÖ Demos y ejemplos de uso

---

## üöÄ Deployment en Producci√≥n

### Opciones de Deployment:

#### 1. Uso Directo (Python)
```python
from predictor import ChicagoCrimePredictor

predictor = ChicagoCrimePredictor("xgboost_chicago", "champion")
prediction = predictor.predict(crime_data)
```

#### 2. API REST (Pr√≥ximo paso opcional)
Crear endpoint Flask/FastAPI:
```python
@app.route('/predict', methods=['POST'])
def predict():
    data = request.json
    prediction = predictor.predict(data)
    return jsonify({'prediction': int(prediction[0])})
```

#### 3. Batch Processing
```python
# Para grandes vol√∫menes de datos
predictions = predictor.batch_predict(large_dataset, batch_size=1000)
```

---

## üìû Soporte

Para problemas o preguntas:
1. Revisar logs de Docker: `docker compose logs -f mlflow`
2. Verificar conectividad: `python mlflow_scripts/verify_mlflow_setup.py`
3. Consultar documentaci√≥n en `../mlflow_system/README.md`

---

## üõ†Ô∏è Stack Tecnol√≥gico

### Infraestructura
- Docker & Docker Compose
- PostgreSQL 15
- MinIO (S3-compatible)
- MLFlow 2.9.2 (servidor) / 3.6.0 (cliente)

### Python
- Python 3.11.13
- scikit-learn 1.7.2
- XGBoost 3.1.2
- pandas 2.3.2
- numpy 2.3.3
- matplotlib 3.10.6
- seaborn 0.13.2

### MLOps
- MLFlow Tracking
- MLFlow Model Registry
- MLFlow Projects (impl√≠cito)
- Artifact Storage (MinIO)
- Metadata Storage (PostgreSQL)

---

## üéì Aprendizajes Clave

### T√©cnicos

1. **MLFlow Version Compatibility**:
   - Cliente 3.6.0 con servidor 2.9.2 requiere workarounds
   - Usar pickle manual para evitar APIs nuevas
   - Deshabilitar autologging para control total

2. **Windows Encoding**:
   - Emojis Unicode causan `UnicodeEncodeError`
   - Soluci√≥n: Redireccionar stdout o usar texto ASCII
   - Configurar `MLFLOW_ENABLE_EMOJI=false`

3. **Model Registry**:
   - Aliases son m√°s flexibles que Stages
   - Backup autom√°tico antes de promoci√≥n
   - Rollback en un comando

4. **M√©tricas para Datos Desbalanceados**:
   - MCC es la m√©trica m√°s robusta
   - Accuracy puede ser enga√±osa
   - AUC complementa bien a MCC

### MLOps

1. **Automatizaci√≥n**:
   - Funciones helper reducen 93% de c√≥digo
   - Estandarizaci√≥n mejora reproducibilidad
   - Comparaci√≥n autom√°tica acelera decisiones

2. **Versionado**:
   - Todos los modelos versionados
   - Historial completo en MLFlow
   - Trazabilidad de cambios

3. **Seguridad**:
   - Backup antes de promoci√≥n
   - Rollback disponible
   - Threshold configurable

---

## üìù Comandos R√°pidos

```bash
# Iniciar infraestructura
cd mlflow_system && docker compose up -d

# Verificar setup
python mlflow_scripts/verify_mlflow_setup.py

# Entrenar todos los modelos
python mlflow_scripts/train_all_8_models.py

# Demo Champion/Challenger
python mlflow_scripts/demo_champion_challenger.py

# Demo Predictor
python mlflow_scripts/demo_predictor.py

# Ver logs
docker compose logs -f mlflow

# Detener todo
docker compose down
```

---
