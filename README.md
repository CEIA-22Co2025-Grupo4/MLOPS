# Chicago Crime Arrest Prediction - MLOps Pipeline

PredicciÃ³n de arrestos en crÃ­menes reportados en la Ciudad de Chicago mediante un pipeline MLOps end-to-end.

## ğŸ‘¥ Autores

- Daniel Eduardo PeÃ±aranda Peralta
- Jorge AdriÃ¡n Alvarez
- MarÃ­a BelÃ©n Cattaneo
- NicolÃ¡s ValentÃ­n Ciarrapico
- Sabrina Daiana Pryszczuk

---

## âš™ï¸ Paso 1: ConfiguraciÃ³n Inicial

### Requisitos

- **Docker** y **Docker Compose** instalados
- **8GB RAM** mÃ­nimo disponible
- **10GB** espacio en disco

### Configurar Socrata API Token (Requerido)

El pipeline ETL descarga datos del **Chicago Data Portal** usando la API de Socrata. **Debes configurar un App Token antes de instalar**.

#### Obtener el Token

1. Ir a https://data.cityofchicago.org/
2. Crear una cuenta o iniciar sesiÃ³n (click en "Sign In" arriba a la derecha)
3. Una vez logueado, ir a tu perfil (click en tu nombre) â†’ **"Developer Settings"**
4. Click en **"Create New App Token"**
5. Completar el formulario:
   - **Application Name**: Nombre descriptivo (ej: "MLOps CEIA")
   - **Description**: DescripciÃ³n breve
   - **Website** (opcional): Puede dejarse vacÃ­o
6. Click en **"Save"** y copiar el **App Token** generado

#### Configurar el Token en el Proyecto

Abrir el archivo `Makefile` y reemplazar el token en la **lÃ­nea 4**:

```makefile
SOCRATA_TOKEN ?= tu_token_generado_aqui
```

> âš ï¸ **Importante**: Sin el token configurado, el pipeline ETL fallarÃ¡ o serÃ¡ extremadamente lento.

### Siguiente paso

Una vez configurado el token, continÃºa con la instalaciÃ³n segÃºn tu sistema operativo:

- **macOS / Linux** â†’ [Ir a instalaciÃ³n](#-paso-2a-instalaciÃ³n-macos--linux)
- **Windows** â†’ [Ir a instalaciÃ³n](#-paso-2b-instalaciÃ³n-windows-wsl2)

---

## ğŸ“¦ Paso 2a: InstalaciÃ³n (macOS / Linux)

```bash
cd MLOPS-main
make install
```

Este comando automÃ¡ticamente:
- Crea directorios necesarios (`airflow/logs`, etc.)
- Configura permisos
- Crea archivo `.env` con configuraciÃ³n por defecto
- Construye todos los contenedores Docker
- Levanta todos los servicios

#### Verificar instalaciÃ³n

```bash
make status
```

Todos los servicios deben mostrar `(healthy)`. Esperar ~2 minutos si algunos servicios aÃºn estÃ¡n iniciando.

#### DesinstalaciÃ³n

```bash
# Limpieza completa (elimina datos, logs, .env)
make uninstall

# Solo detener servicios (mantiene datos)
make down
```

**Siguiente paso** â†’ [Ir a EjecuciÃ³n](#-paso-3-ejecuciÃ³n)

---

## ğŸ“¦ Paso 2b: InstalaciÃ³n (Windows WSL2)

Windows requiere **WSL2** (Windows Subsystem for Linux) ya que el proyecto usa comandos Unix.

### 1. Instalar WSL2

```powershell
# En PowerShell como Administrador
wsl --install
```

Reiniciar el equipo despuÃ©s de la instalaciÃ³n.

### 2. Instalar Docker Desktop

1. Descargar [Docker Desktop](https://www.docker.com/products/docker-desktop/)
2. Durante la instalaciÃ³n, habilitar **WSL2 backend**
3. En Docker Desktop â†’ Settings â†’ Resources â†’ WSL Integration â†’ Habilitar para tu distro

### 3. Instalar el proyecto

```bash
# Abrir terminal WSL2 (Ubuntu)
wsl

# Navegar al proyecto
cd /mnt/c/Users/TuUsuario/MLOPS-main

# Instalar
make install
```

### 4. Verificar

```bash
make status
```

Todos los servicios deben mostrar `(healthy)`.

### DesinstalaciÃ³n

```bash
wsl
make uninstall
```

**Siguiente paso** â†’ [Ir a EjecuciÃ³n](#-paso-3-ejecuciÃ³n)

---

## ğŸ”„ Paso 3: EjecuciÃ³n

### Servicios disponibles

| Servicio | URL | Credenciales |
|----------|-----|--------------|
| Airflow | http://localhost:8080 | `airflow` / `airflow` |
| MLflow | http://localhost:5001 | â€” |
| MinIO | http://localhost:9001 | `minio` / `minio123` |
| API | http://localhost:8800/docs | â€” |

### Comandos (ejecutar en orden)

```bash
make airflow    # 1. Abrir Airflow â†’ ejecutar DAG 'etl_with_taskflow' â†’ esperar ~15min
make train      # 2. Entrenar modelo XGBoost
make champion   # 3. Asignar como champion
make reload     # 4. Cargar modelo en API
make api        # 5. Abrir documentaciÃ³n API
```

<details>
<summary><strong>Detalles de cada paso (click para expandir)</strong></summary>

#### 1. Ejecutar ETL Pipeline

En la UI de Airflow (http://localhost:8080):
- Buscar DAG: `etl_with_taskflow`
- Activar el toggle (si estÃ¡ pausado)
- Click â–¶ï¸ para ejecutar
- Esperar ~10-15 minutos hasta que todas las tareas estÃ©n en verde âœ…

#### 2. Entrenar modelo

El comando `make train` entrena un modelo XGBoost y lo registra en MLflow.

#### 3. Asignar modelo como Champion

El comando `make champion` asigna el alias `champion` a la Ãºltima versiÃ³n del modelo.

#### 4. Cargar modelo en API

El comando `make reload` carga el modelo champion en la API.

#### 5. Usar la API

Ejemplo de predicciÃ³n con cURL:

```bash
curl -X POST "http://localhost:8800/predict" \
  -H "Content-Type: application/json" \
  -d '{
    "iucr_freq": 0.03,
    "primary_type_freq": 0.1,
    "location_description_freq": 0.05,
    "day_of_week_sin": 0.5,
    "x_coordinate_standardized": 0.12,
    "y_coordinate_standardized": -0.34,
    "distance_crime_to_police_station_standardized": 0.56
  }'
```

</details>

---

## ğŸ“‹ Comandos Disponibles

```bash
make help         # Ver todos los comandos

# InstalaciÃ³n
make install      # InstalaciÃ³n completa
make uninstall    # DesinstalaciÃ³n completa
make setup        # Solo crear directorios y .env

# Servicios
make up           # Iniciar servicios
make down         # Detener servicios
make restart      # Reiniciar servicios
make status       # Ver estado
make logs         # Ver logs en tiempo real
make clean        # Eliminar contenedores y volÃºmenes

# ML Pipeline
make train        # Entrenar modelo XGBoost
make champion     # Asignar modelo como champion
make reload       # Recargar modelo en API
make drift        # Ver instrucciones de drift monitoring

# Abrir interfaces
make airflow      # http://localhost:8080
make mlflow       # http://localhost:5001
make minio        # http://localhost:9001
make api          # http://localhost:8800/docs
```

---

## ğŸ—ï¸ Arquitectura

<details>
<summary><strong>Click para expandir</strong></summary>

### Estructura del Proyecto

```
MLOPS-main/
â”œâ”€â”€ src/                          # CÃ³digo fuente
â”‚   â”œâ”€â”€ api/                      # FastAPI
â”‚   â”‚   â”œâ”€â”€ app.py
â”‚   â”‚   â””â”€â”€ preprocessing.py      # Preprocesamiento para inference
â”‚   â””â”€â”€ training/                 # Scripts ML
â”‚       â”œâ”€â”€ train_xgboost.py
â”‚       â”œâ”€â”€ champion_challenger.py
â”‚       â””â”€â”€ predictor.py
â”œâ”€â”€ airflow/                      # Apache Airflow
â”‚   â”œâ”€â”€ dags/
â”‚   â”‚   â”œâ”€â”€ etl_process_taskflow.py
â”‚   â”‚   â”œâ”€â”€ drift_process_taskflow.py  # Drift monitoring
â”‚   â”‚   â””â”€â”€ etl_helpers/
â”‚   â”‚       â”œâ”€â”€ inference_preprocessing.py
â”‚   â”‚       â””â”€â”€ ...
â”‚   â””â”€â”€ secrets/
â”œâ”€â”€ docker/                       # Dockerfiles
â”‚   â”œâ”€â”€ airflow/
â”‚   â”œâ”€â”€ fastapi/
â”‚   â”œâ”€â”€ mlflow/
â”‚   â”œâ”€â”€ postgres/
â”‚   â””â”€â”€ trainer/
â”œâ”€â”€ tests/
â”œâ”€â”€ docs/
â”œâ”€â”€ docker-compose.yaml
â”œâ”€â”€ Makefile
â””â”€â”€ README.md
```

### Flujo MLOps

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”     â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”     â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”     â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  ETL        â”‚ â”€â”€â–¶ â”‚  Training   â”‚ â”€â”€â–¶ â”‚  Registry   â”‚ â”€â”€â–¶ â”‚  Serving    â”‚
â”‚  (Airflow)  â”‚     â”‚  (XGBoost)  â”‚     â”‚  (MLflow)   â”‚     â”‚  (FastAPI)  â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜     â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜     â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜     â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
     â”‚                    â”‚                   â”‚                   â”‚
     â–¼                    â–¼                   â–¼                   â–¼
  MinIO               MLflow              Model              /predict
  s3://data          Tracking            Registry           Endpoint
                                                                 â”‚
                          â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                          â–¼
                   â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
                   â”‚   Drift     â”‚  â—€â”€â”€ Weekly monitoring
                   â”‚  Monitoring â”‚
                   â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                          â”‚
                          â–¼
                   Retrain if needed
```

</details>

---

## ğŸŒ API Reference

<details>
<summary><strong>Click para expandir</strong></summary>

### Endpoints

| MÃ©todo | Endpoint | DescripciÃ³n |
|--------|----------|-------------|
| GET | `/health` | Health check |
| POST | `/predict` | PredicciÃ³n individual (features preprocesadas) |
| POST | `/predict/batch` | PredicciÃ³n por lote (features preprocesadas, max 1000) |
| POST | `/predict/raw` | PredicciÃ³n individual (datos crudos) |
| POST | `/predict/raw/batch` | PredicciÃ³n por lote (datos crudos, max 1000) |
| GET | `/model/info` | Info del modelo |
| POST | `/model/reload` | Recargar modelo |

### PredicciÃ³n con datos crudos

Los endpoints `/predict/raw` y `/predict/raw/batch` aceptan datos sin preprocesar:

```bash
curl -X POST "http://localhost:8800/predict/raw" \
  -H "Content-Type: application/json" \
  -d '{
    "iucr": "0820",
    "primary_type": "THEFT",
    "location_description": "STREET",
    "date": "2024-01-15 14:30:00",
    "x_coordinate": 1176096.0,
    "y_coordinate": 1912547.0,
    "distance_crime_to_police_station": 1250.5
  }'
```

### Input Features (7 total)

| Feature | DescripciÃ³n |
|---------|-------------|
| `iucr_freq` | Frequency encoding del cÃ³digo IUCR |
| `primary_type_freq` | Frequency encoding del tipo de crimen |
| `location_description_freq` | Frequency encoding de la ubicaciÃ³n |
| `day_of_week_sin` | Encoding cÃ­clico del dÃ­a de semana |
| `x_coordinate_standardized` | Coordenada X estandarizada |
| `y_coordinate_standardized` | Coordenada Y estandarizada |
| `distance_crime_to_police_station_standardized` | Distancia a comisarÃ­a (estandarizada) |

### Ejemplo Response

```json
{
  "prediction": true,
  "probability": 0.78,
  "model_version": "2",
  "timestamp": "2025-12-14T15:30:00Z"
}
```

</details>

---

## ğŸ”§ ETL Pipeline

<details>
<summary><strong>Click para expandir</strong></summary>

### Etapas

1. **Setup S3** - Crea buckets en MinIO
2. **Download Data** - Descarga datos de Chicago Data Portal
3. **Enrich Data** - Agrega features geoespaciales y temporales
4. **Split Data** - DivisiÃ³n train/test (80/20)
5. **Process Outliers** - Manejo de outliers
6. **Encode Data** - Encoding de categÃ³ricas
7. **Scale Data** - EstandarizaciÃ³n
8. **Balance Data** - SMOTE + Undersampling
9. **Extract Features** - SelecciÃ³n con Mutual Information
10. **Pipeline Summary** - MÃ©tricas consolidadas

### Datos de salida

```
s3://data/ml-ready-data/
â”œâ”€â”€ train_{date}.csv    # ~173k registros Ã— 7 features
â””â”€â”€ test_{date}.csv     # ~46k registros Ã— 7 features
```

</details>

---

## ğŸ“Š Drift Monitoring

<details>
<summary><strong>Click para expandir</strong></summary>

### Prerequisitos

Antes de ejecutar drift monitoring, es necesario:

1. **Ejecutar el ETL** - Para tener datos de entrenamiento
2. **Entrenar el modelo** - `make train` crea el archivo de referencia automÃ¡ticamente
3. **Tener el modelo en la API** - `make champion && make reload`

### Primera EjecuciÃ³n

Si ejecutas el DAG de drift **sin haber entrenado el modelo**, verÃ¡s este warning:

```
NO REFERENCE DATA AVAILABLE
Drift monitoring requires a reference dataset from training.
Please run 'make train' to create the reference data.
```

**SoluciÃ³n**: Ejecuta `make train` primero. El entrenamiento crea automÃ¡ticamente el archivo `drift/reference/reference_{fecha}.csv`.

### EjecuciÃ³n Normal

Una vez que existe el archivo de referencia:

1. Ir a Airflow: http://localhost:8080
2. Buscar DAG: `drift_with_taskflow`
3. Click en "Trigger DAG" (play button)
4. Configurar parÃ¡metros si es necesario (ver abajo)
5. Click "Trigger"

### ParÃ¡metros del DAG

| ParÃ¡metro | Default | DescripciÃ³n |
|-----------|---------|-------------|
| `test_mode` | `false` | Si es `true`, usa delay mÃ­nimo de 2 dÃ­as (para testing) |
| `data_delay_days` | `null` | Override manual del delay (null = usar config) |

**Para testing** (datos mÃ¡s recientes):
```
test_mode: true
```

**Para override especÃ­fico**:
```
data_delay_days: 3
```

### QuÃ© hace el DAG

1. **Descarga datos recientes** de Chicago Data Portal (Ãºltimos 7 dÃ­as, con delay configurable)
2. **Preprocesa** los datos (encoding, scaling) igual que en entrenamiento
3. **Obtiene predicciones** del modelo via API (`/predict/batch`)
4. **Calcula mÃ©tricas de drift**:
   - **Feature Drift** (PSI, KS-test) - cambios en distribuciÃ³n de features
   - **Prediction Drift** - cambios en distribuciÃ³n de predicciones
   - **Concept Drift** - degradaciÃ³n de accuracy (si hay labels)
5. **Alerta** si se detecta drift significativo

### Tipos de Drift y Umbrales

| Tipo | MÃ©trica | Umbral | InterpretaciÃ³n |
|------|---------|--------|----------------|
| Feature Drift | PSI | > 0.2 | Cambio significativo en distribuciÃ³n |
| Feature Drift | KS | > 0.1 | Test Kolmogorov-Smirnov significativo |
| Concept Drift | Accuracy Delta | > 0.05 | DegradaciÃ³n de accuracy vs referencia |

**PSI (Population Stability Index)**:
- < 0.1: Sin cambio significativo
- 0.1 - 0.2: Cambio moderado
- \> 0.2: Cambio significativo (requiere atenciÃ³n)

### Archivos generados

```
s3://data/drift/
â”œâ”€â”€ reference/
â”‚   â””â”€â”€ reference_{fecha}.csv  # Creado por make train
â”œâ”€â”€ current/
â”‚   â””â”€â”€ current_{fecha}.csv    # Datos actuales (cada ejecuciÃ³n)
â””â”€â”€ results/
    â””â”€â”€ drift_{fecha}.csv      # MÃ©tricas de drift
```

### Flujo Completo (Nuevo Proyecto)

```bash
# 1. Instalar y levantar servicios
make install

# 2. Ejecutar ETL (en Airflow UI)
make airflow
# -> Trigger 'etl_with_taskflow', esperar ~15 min

# 3. Entrenar modelo (crea referencia automÃ¡ticamente)
make train

# 4. Configurar modelo en API
make champion
make reload

# 5. Ejecutar drift monitoring (en Airflow UI)
# -> Trigger 'drift_with_taskflow' con test_mode: true
```

### Troubleshooting

**Error: "No crime data available for period..."**
- Chicago Data Portal tiene delay de publicaciÃ³n (3-7 dÃ­as)
- SoluciÃ³n: Aumentar `data_delay_days` o usar datos de fecha anterior

**Error: "No reference dataset found..."**
- No se ha entrenado el modelo
- SoluciÃ³n: Ejecutar `make train`

**Error: "API call failed..."**
- El modelo no estÃ¡ cargado en la API
- SoluciÃ³n: `make champion && make reload`

</details>

---

## ğŸ†˜ Troubleshooting

<details>
<summary><strong>Click para expandir</strong></summary>

### Servicios no inician

```bash
make logs      # Ver logs
make restart   # Reiniciar
```

### Permisos en airflow/logs (Linux/Mac)

```bash
sudo chmod 777 airflow/logs
make restart
```

### Puerto 5000 ocupado (macOS)

MLflow usa puerto 5001 por defecto para evitar conflicto con AirPlay.

### ETL falla en download_data

Verificar que el Socrata Token estÃ¡ configurado correctamente en el `Makefile`.

### ETL falla en balance_data

Verificar que el ETL completo se ejecutÃ³. Si hay errores previos, los datos pueden tener NaN.

### Modelo no carga en API

```bash
make champion  # Verificar que existe el alias
make reload    # Recargar
```

### Windows: make command not found

Usar WSL2:
```bash
wsl
cd /mnt/c/path/to/MLOPS-main
make install
```

</details>

---

## ğŸ“š DocumentaciÃ³n Adicional

- [Consigna del Proyecto](docs/CONSIGNAS.md)
- [API Documentation](http://localhost:8800/docs) (requiere servicios activos)
- [MLflow UI](http://localhost:5001) (requiere servicios activos)

---

## ğŸ“„ Licencia

MIT License - Ver archivo [LICENSE](LICENSE)
