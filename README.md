# Proyecto Final ‚Äì Operaciones de aprendizaje autom√°tico I
### Implementaci√≥n en ambiente productivo de un modelo de ML para la Predicci√≥n de Arrestos en Cr√≠menes Reportados en la Ciudad de Chicago

## Descripci√≥n General

Este proyecto implementa un **pipeline de Machine Learning end-to-end** orientado a la predicci√≥n de la probabilidad de que **un delito registrado en la ciudad de Chicago** derive en un arresto.
El modelo utiliza un conjunto de variables dise√±adas para capturar informaci√≥n clave del evento delictivo, entre ellas:

* **Caracter√≠sticas del crimen**: c√≥digo IUCR, categor√≠a primaria, clasificaci√≥n del FBI y tipo de delito.
* **Informaci√≥n geoespacial**: coordenadas del incidente, distrito policial, √°rea comunitaria y otros atributos territoriales.
* **Contexto temporal**: fecha y hora del hecho, d√≠a de la semana, estaci√≥n del a√±o y otras transformaciones temporales relevantes.
* **Proximidad operativa**: distancia al destacamento policial m√°s cercano, incorporada como feature para capturar la influencia de la presencia policial.

## Objetivo del modelo

El objetivo del modelo es estimar la probabilidad de arresto asociado a un incidente delictivo en la ciudad de Chicago, utilizando un enfoque supervisado de clasificaci√≥n.
El sistema toma como entrada los registros hist√≥ricos del Chicago Police Department y genera predicciones basadas en un conjunto de features que integran informaci√≥n criminal, espacial, temporal y operativa (presencia policial).
Este modelo constituye el n√∫cleo del pipeline, sobre el cual se montan las tareas de entrenamiento, validaci√≥n, seguimiento y despliegue

---

## üë©‚Äçüíª Autores

- **Daniel Eduardo Pe√±aranda Peralta**
- **Jorge Adri√°n Alvarez**
- **Mar√≠a Bel√©n Cattaneo**
- **Nicol√°s Valent√≠n Ciarrapico**
- **Sabrina Daiana Pryszczuk**

---

## üìã Tabla de Contenidos

1. [Arquitectura del Sistema](#-arquitectura-del-sistema)
2. [Instalaci√≥n](#-instalaci√≥n)
3. [Flujo de Trabajo Completo](#-flujo-de-trabajo-completo)
4. [ETL Pipeline](#-etl-pipeline)
5. [Experimentaci√≥n y Entrenamiento](#-experimentaci√≥n-y-entrenamiento)
6. [Despliegue del Modelo](#-despliegue-del-modelo)
7. [API de Predicci√≥n](#-api-de-predicci√≥n)
8. [Monitoreo y MLflow](#-monitoreo-y-mlflow)
9. [Comandos √ötiles](#-comandos-√∫tiles)
10. [Configuraci√≥n Avanzada](#-configuraci√≥n-avanzada)

---

## üèóÔ∏è Arquitectura del Sistema

Este proyecto implementa un pipeline MLOps completo con los siguientes servicios:

- **[Apache Airflow](https://airflow.apache.org/)** - Orquestaci√≥n de ETL y reentrenamiento
- **[MLflow](https://mlflow.org/)** - Tracking de experimentos y registro de modelos
- **[FastAPI](https://fastapi.tiangolo.com/)** - API REST para servir predicciones
- **[MinIO](https://min.io/)** - Almacenamiento de objetos S3-compatible
- **[PostgreSQL](https://www.postgresql.org/)** - Base de datos relacional
- **[ValKey](https://valkey.io/)** - Base de datos key-value (Redis fork)

![Diagrama de servicios](final_assign.png)

### Recursos Creados Autom√°ticamente

**Buckets MinIO:**
- `s3://data` - Almacenamiento de datos del pipeline ETL
- `s3://mlflow` - Artefactos de experimentos y modelos

**Bases de Datos PostgreSQL:**
- `mlflow_db` - Metadata de MLflow
- `airflow` - Metadata de Airflow

---

## üöÄ Instalaci√≥n

### Requisitos Previos

- [Docker](https://docs.docker.com/engine/install/) instalado
- Al menos 8GB RAM disponible
- 10GB espacio en disco

### Pasos de Instalaci√≥n

1. **Clonar el repositorio:**
   ```bash
   git clone <repository-url>
   cd MLOPS
   ```

2. **Configurar permisos (Linux/MacOS):**
   ```bash
   # Crear carpetas necesarias
   mkdir -p airflow/{config,dags,logs,plugins}

   # Configurar UID en .env (encuentra tu UID con: id -u)
   echo "AIRFLOW_UID=$(id -u)" >> .env
   ```

3. **Configurar variables de entorno:**

   Edita el archivo `.env` y a√±ade tu token de Socrata API:
   ```bash
   SOCRATA_APP_TOKEN=tu_token_aqui
   ```

   Obt√©n tu token gratis en: https://data.cityofchicago.org/

4. **Levantar servicios:**
   ```bash
   make install && make up
   ```

   O usando docker-compose directamente:
   ```bash
   docker compose --profile all up
   ```

5. **Verificar estado:**
   ```bash
   docker ps -a  # Todos los servicios deben estar "healthy"
   ```

6. **Acceder a las interfaces:**
   - **Airflow UI:** http://localhost:8080 (user: `airflow`, pass: `airflow`)
   - **MLflow UI:** http://localhost:5001
   - **MinIO Console:** http://localhost:9001 (user: `minio`, pass: `minio123`)
   - **API Docs:** http://localhost:8800/docs
   - **API:** http://localhost:8800

> **Nota:** Si usas un servidor remoto, reemplaza `localhost` por la IP del servidor.

---

## üîÑ Flujo de Trabajo Completo

Este proyecto sigue un flujo MLOps end-to-end:

```
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ                     1. ETL PIPELINE (Airflow)                   ‚îÇ
‚îÇ  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê   ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê   ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê   ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê    ‚îÇ
‚îÇ  ‚îÇ Download ‚îÇ ‚Üí ‚îÇ Enrich   ‚îÇ ‚Üí ‚îÇ Process  ‚îÇ ‚Üí ‚îÇ ML-Ready ‚îÇ    ‚îÇ
‚îÇ  ‚îÇ   Data   ‚îÇ   ‚îÇ   Data   ‚îÇ   ‚îÇ   Data   ‚îÇ   ‚îÇ   Data   ‚îÇ    ‚îÇ
‚îÇ  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò   ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò   ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò   ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò    ‚îÇ
‚îÇ       ‚Üì              ‚Üì              ‚Üì              ‚Üì            ‚îÇ
‚îÇ  [Raw Data]   [Enriched Data] [Processed]  [Train/Test]        ‚îÇ
‚îÇ   MinIO s3://data/                                              ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
                            ‚Üì
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ              2. EXPERIMENTACI√ìN (Notebooks/Scripts)             ‚îÇ
‚îÇ  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê   ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê   ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê       ‚îÇ
‚îÇ  ‚îÇ Experiment 1 ‚îÇ   ‚îÇ Experiment 2 ‚îÇ   ‚îÇ Experiment N ‚îÇ       ‚îÇ
‚îÇ  ‚îÇ (Logistic    ‚îÇ   ‚îÇ (Random      ‚îÇ   ‚îÇ (XGBoost)    ‚îÇ       ‚îÇ
‚îÇ  ‚îÇ  Regression) ‚îÇ   ‚îÇ  Forest)     ‚îÇ   ‚îÇ              ‚îÇ       ‚îÇ
‚îÇ  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò   ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò   ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò       ‚îÇ
‚îÇ         ‚Üì                  ‚Üì                  ‚Üì                 ‚îÇ
‚îÇ     MLflow Tracking UI - Comparaci√≥n de m√©tricas               ‚îÇ
‚îÇ  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê       ‚îÇ
‚îÇ  ‚îÇ Metrics: Accuracy, Precision, Recall, F1, AUC       ‚îÇ       ‚îÇ
‚îÇ  ‚îÇ Params: Hyperparameters, Features, Data version     ‚îÇ       ‚îÇ
‚îÇ  ‚îÇ Artifacts: Model, Charts, Feature importance        ‚îÇ       ‚îÇ
‚îÇ  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò       ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
                            ‚Üì
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ                3. REGISTRO DE MODELO (MLflow)                   ‚îÇ
‚îÇ  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê        ‚îÇ
‚îÇ  ‚îÇ Seleccionar mejor modelo ‚Üí Register ‚Üí Production   ‚îÇ        ‚îÇ
‚îÇ  ‚îÇ Model Registry: Versioning, Staging, Production    ‚îÇ        ‚îÇ
‚îÇ  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò        ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
                            ‚Üì
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ                  4. DESPLIEGUE (FastAPI)                        ‚îÇ
‚îÇ  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê          ‚îÇ
‚îÇ  ‚îÇ  API carga modelo desde MLflow Model Registry    ‚îÇ          ‚îÇ
‚îÇ  ‚îÇ  Endpoints:                                       ‚îÇ          ‚îÇ
‚îÇ  ‚îÇ  - POST /predict - Predicci√≥n individual         ‚îÇ          ‚îÇ
‚îÇ  ‚îÇ  - POST /predict/batch - Predicci√≥n por lote     ‚îÇ          ‚îÇ
‚îÇ  ‚îÇ  - GET /model/info - Info del modelo en uso      ‚îÇ          ‚îÇ
‚îÇ  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò          ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
                            ‚Üì
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ              5. MONITOREO Y REENTRENAMIENTO                     ‚îÇ
‚îÇ  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê          ‚îÇ
‚îÇ  ‚îÇ  - Data drift monitoring                         ‚îÇ          ‚îÇ
‚îÇ  ‚îÇ  - Model performance tracking                    ‚îÇ          ‚îÇ
‚îÇ  ‚îÇ  - Automated retraining (Airflow DAG)            ‚îÇ          ‚îÇ
‚îÇ  ‚îÇ  - A/B testing (Champion/Challenger)             ‚îÇ          ‚îÇ
‚îÇ  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò          ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
```

---

## üîß ETL Pipeline

### Descripci√≥n General

Pipeline ETL automatizado que procesa datos de cr√≠menes de Chicago desde la API p√∫blica hasta datasets ML-ready.

### Arquitectura del Pipeline

```
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê   ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê   ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê   ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ   Setup     ‚îÇ ‚Üí ‚îÇ  Download   ‚îÇ ‚Üí ‚îÇ   Enrich    ‚îÇ ‚Üí ‚îÇ    Split    ‚îÇ
‚îÇ     S3      ‚îÇ   ‚îÇ    Data     ‚îÇ   ‚îÇ    Data     ‚îÇ   ‚îÇ    Data     ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò   ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò   ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò   ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
                                                              ‚Üì
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê   ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê   ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê   ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ   Extract   ‚îÇ ‚Üê ‚îÇ   Balance   ‚îÇ ‚Üê ‚îÇ    Scale    ‚îÇ ‚Üê ‚îÇ   Encode    ‚îÇ
‚îÇ  Features   ‚îÇ   ‚îÇ    Data     ‚îÇ   ‚îÇ    Data     ‚îÇ   ‚îÇ    Data     ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò   ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò   ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò   ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
      ‚Üì
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ   Pipeline  ‚îÇ
‚îÇ   Summary   ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
```

### Etapas del Pipeline

#### 1Ô∏è‚É£ Setup S3
- Crea bucket MinIO si no existe
- Configura pol√≠tica de lifecycle (TTL 60 d√≠as para datos temporales)

#### 2Ô∏è‚É£ Download Data
- **Fuente:** [Chicago Data Portal](https://data.cityofchicago.org/) via Socrata API
- **Descarga inicial:** A√±o completo (~450k registros)
- **Descargas subsecuentes:** Incremental mensual (~35k registros)
- **Output:** `s3://data/0-raw-data/monthly-data/{YYYY-MM}/crimes.csv`

#### 3Ô∏è‚É£ Enrich Data
- **Geoespacial:** Distancia a estaci√≥n policial m√°s cercana (GeoPandas)
- **Temporal:**
  - Season (Winter/Spring/Summer/Fall)
  - Day of week (0=Monday, 6=Sunday)
  - Day time (Morning/Afternoon/Evening/Night)
- **Limpieza:** Duplicados, valores nulos
- **Output:** `s3://data/1-enriched-data/crimes_enriched_{date}.csv`
- **Monitoring:** Logs raw data quality metrics to MLflow

#### 4Ô∏è‚É£ Split Data
- **Estrategia:** Stratified train/test split (80/20)
- **Target:** `arrest` (boolean)
- **Output:**
  - `s3://data/2-split-data/crimes_train_{date}.csv`
  - `s3://data/2-split-data/crimes_test_{date}.csv`
- **Monitoring:** Logs class distribution to MLflow

#### 5Ô∏è‚É£ Process Outliers
- **M√©todo:** IQR-based outlier removal
- **Log transformation:** `distance_crime_to_police_station`
- **Output:** `s3://data/3-outliers-data/`

#### 6Ô∏è‚É£ Encode Data
- **One-hot:** Low cardinality (season, day_time)
- **Frequency:** High cardinality (primary_type, location_description)
- **Cyclic:** Day of week (sine transformation)
- **Label:** Boolean features (domestic)
- **Output:** `s3://data/4-encoded-data/`

#### 7Ô∏è‚É£ Scale Data
- **M√©todo:** StandardScaler (zero mean, unit variance)
- **Features:** Numeric only (coordinates, distances)
- **Output:** `s3://data/5-scaled-data/`

#### 8Ô∏è‚É£ Balance Data
- **Problema:** ~84% no arrest, ~16% arrest
- **Soluci√≥n:** SMOTE + RandomUnderSampler
  - SMOTE: Oversample minority to 50% of majority
  - Undersampling: Final ratio 80% (minority = 80% of majority)
- **Output:** `s3://data/6-balanced-data/`
- **Monitoring:** Logs balancing impact to MLflow

#### 9Ô∏è‚É£ Extract Features
- **M√©todo:** Mutual Information feature selection
- **Threshold:** MI score > 0.05
- **Features finales:** ~11 features (de ~20 originales)
- **Output:** `s3://data/ml-ready-data/train_{date}.csv`
- **Monitoring:** Logs feature importance and correlation to MLflow

#### üîü Pipeline Summary
- **Consolidaci√≥n:** M√©tricas de todo el pipeline
- **Visualizaci√≥n:** Flow chart mostrando transformaci√≥n de datos
- **Output:** MLflow run con pipeline overview

### Estructura de Datos en MinIO

```
s3://data/
‚îú‚îÄ‚îÄ 0-raw-data/
‚îÇ   ‚îî‚îÄ‚îÄ monthly-data/
‚îÇ       ‚îî‚îÄ‚îÄ {YYYY-MM}/
‚îÇ           ‚îú‚îÄ‚îÄ crimes.csv              # ~35k registros/mes
‚îÇ           ‚îî‚îÄ‚îÄ police_stations.csv     # 23 estaciones
‚îú‚îÄ‚îÄ 1-enriched-data/
‚îÇ   ‚îî‚îÄ‚îÄ crimes_enriched_{date}.csv      # +3 features temporales
‚îú‚îÄ‚îÄ 2-split-data/
‚îÇ   ‚îú‚îÄ‚îÄ crimes_train_{date}.csv         # 80%
‚îÇ   ‚îî‚îÄ‚îÄ crimes_test_{date}.csv          # 20%
‚îú‚îÄ‚îÄ 3-outliers-data/
‚îÇ   ‚îú‚îÄ‚îÄ train_{date}.csv
‚îÇ   ‚îî‚îÄ‚îÄ test_{date}.csv
‚îú‚îÄ‚îÄ 4-encoded-data/
‚îÇ   ‚îú‚îÄ‚îÄ train_{date}.csv
‚îÇ   ‚îî‚îÄ‚îÄ test_{date}.csv
‚îú‚îÄ‚îÄ 5-scaled-data/
‚îÇ   ‚îú‚îÄ‚îÄ train_{date}.csv
‚îÇ   ‚îî‚îÄ‚îÄ test_{date}.csv
‚îú‚îÄ‚îÄ 6-balanced-data/
‚îÇ   ‚îú‚îÄ‚îÄ train_{date}.csv                # ~173k registros (balanced)
‚îÇ   ‚îî‚îÄ‚îÄ test_{date}.csv
‚îî‚îÄ‚îÄ ml-ready-data/                      # ‚≠ê USAR ESTE PARA EXPERIMENTS
    ‚îú‚îÄ‚îÄ train_{date}.csv                # ~173k √ó 11 features
    ‚îî‚îÄ‚îÄ test_{date}.csv                 # ~46k √ó 11 features
```

### Ejecuci√≥n del Pipeline

**Trigger manual en Airflow UI:**
1. Navegar a http://localhost:8080
2. Buscar DAG: `etl_with_taskflow`
3. Click en ‚ñ∂Ô∏è (Play) para ejecutar

**Schedule autom√°tico:**
- **Frecuencia:** `@monthly` (primer d√≠a de cada mes a las 00:00)
- **Catchup:** Habilitado (procesa meses faltantes)
- **Max Active Runs:** 1 (evita ejecuciones concurrentes)

### Monitoreo del Pipeline

Cada etapa del pipeline registra m√©tricas en **MLflow**:

**Runs creados autom√°ticamente:**
- `raw_data_{date}` - Calidad de datos crudos
- `split_{date}` - Distribuci√≥n train/test
- `balance_{date}` - Impacto del balanceo
- `features_{date}` - Feature selection results
- `pipeline_summary_{date}` - Overview completo

**Artifacts en MLflow:**
- `charts/raw_data_overview.png` - 4 gr√°ficos de datos crudos
- `charts/split_distribution.png` - Comparaci√≥n train/test
- `charts/balance_comparison.png` - Antes/despu√©s balanceo
- `charts/feature_importance.png` - Top 10 features (MI score)
- `charts/correlation_heatmap.png` - Correlaci√≥n entre features
- `charts/pipeline_flow.png` - ‚≠ê Data flow completo

---

## üß™ Experimentaci√≥n y Entrenamiento

### Acceso a Datos ML-Ready

Los datos procesados est√°n disponibles en MinIO para tus experimentos:

```python
import os
import pandas as pd
import boto3

# Configurar conexi√≥n a MinIO
os.environ["AWS_ACCESS_KEY_ID"] = "minio"
os.environ["AWS_SECRET_ACCESS_KEY"] = "minio123"
os.environ["AWS_ENDPOINT_URL_S3"] = "http://localhost:9000"

# Descargar datos
s3 = boto3.client('s3', endpoint_url='http://localhost:9000')

# Usar la √∫ltima versi√≥n disponible (o especificar fecha)
train_df = pd.read_csv('s3://data/ml-ready-data/train_2025-11-22.csv')
test_df = pd.read_csv('s3://data/ml-ready-data/test_2025-11-22.csv')

# Separar features y target
X_train = train_df.drop('arrest', axis=1)
y_train = train_df['arrest']
X_test = test_df.drop('arrest', axis=1)
y_test = test_df['arrest']
```

### Template de Experimentaci√≥n

Ejemplo de experimento con tracking en MLflow:

```python
import mlflow
import mlflow.sklearn
from sklearn.linear_model import LogisticRegression
from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, roc_auc_score

# Configurar MLflow
mlflow.set_tracking_uri("http://localhost:5001")
mlflow.set_experiment("chicago-crime-arrest-prediction")

# Iniciar run
with mlflow.start_run(run_name="logistic_regression_baseline"):

    # Log parameters
    params = {
        "model_type": "LogisticRegression",
        "solver": "lbfgs",
        "max_iter": 1000,
        "class_weight": "balanced",
        "data_version": "2025-11-22"
    }
    mlflow.log_params(params)

    # Entrenar modelo
    model = LogisticRegression(**{k: v for k, v in params.items()
                                   if k not in ['model_type', 'data_version']})
    model.fit(X_train, y_train)

    # Predecir
    y_pred = model.predict(X_test)
    y_pred_proba = model.predict_proba(X_test)[:, 1]

    # Log metrics
    metrics = {
        "accuracy": accuracy_score(y_test, y_pred),
        "precision": precision_score(y_test, y_pred),
        "recall": recall_score(y_test, y_pred),
        "f1": f1_score(y_test, y_pred),
        "roc_auc": roc_auc_score(y_test, y_pred_proba)
    }
    mlflow.log_metrics(metrics)

    # Log model
    mlflow.sklearn.log_model(
        model,
        "model",
        registered_model_name="chicago-crime-arrest-predictor"
    )

    print(f"‚úÖ Experiment logged to MLflow: {mlflow.active_run().info.run_id}")
```

### Comparaci√≥n de Experimentos

Accede a MLflow UI para comparar experimentos:

1. **Navegar a:** http://localhost:5001
2. **Seleccionar experimento:** `chicago-crime-arrest-prediction`
3. **Comparar runs:** Seleccionar m√∫ltiples runs y click en "Compare"
4. **Visualizar:**
   - Parallel coordinates plot
   - Scatter plot (metric vs metric)
   - Metric history
   - Artifact comparison

### Modelos Sugeridos para Experimentar

| Modelo | Fortalezas | Hiperpar√°metros clave |
|--------|------------|----------------------|
| Logistic Regression | Baseline r√°pido, interpretable | `C`, `solver`, `class_weight` |
| Random Forest | Robusto, feature importance | `n_estimators`, `max_depth`, `min_samples_split` |
| XGBoost | Alto rendimiento, manejo de desbalance | `learning_rate`, `max_depth`, `scale_pos_weight` |
| LightGBM | R√°pido, eficiente en memoria | `num_leaves`, `learning_rate`, `feature_fraction` |
| CatBoost | Manejo autom√°tico de categ√≥ricas | `iterations`, `learning_rate`, `depth` |

---

## üöÄ Despliegue del Modelo

### Registro del Modelo en MLflow

1. **Entrenar y loguear modelo** (ver secci√≥n Experimentaci√≥n)

2. **Registrar modelo en Model Registry:**
   ```python
   # Opci√≥n 1: Durante el training
   mlflow.sklearn.log_model(
       model,
       "model",
       registered_model_name="chicago-crime-arrest-predictor"
   )

   # Opci√≥n 2: Desde run existente
   run_id = "abc123..."
   model_uri = f"runs:/{run_id}/model"
   mlflow.register_model(model_uri, "chicago-crime-arrest-predictor")
   ```

3. **Promover a Production:**
   ```python
   from mlflow.tracking import MlflowClient

   client = MlflowClient()

   # Obtener √∫ltima versi√≥n
   model_name = "chicago-crime-arrest-predictor"
   latest_version = client.get_latest_versions(model_name, stages=["None"])[0]

   # Promover a Production
   client.transition_model_version_stage(
       name=model_name,
       version=latest_version.version,
       stage="Production"
   )
   ```

### FastAPI - Carga del Modelo

La API carga autom√°ticamente el modelo en stage "Production" desde MLflow:

```python
# En dockerfiles/fastapi/app/main.py
import mlflow.pyfunc

MODEL_NAME = "chicago-crime-arrest-predictor"
model = mlflow.pyfunc.load_model(f"models:/{MODEL_NAME}/Production")
```

---

## üåê API de Predicci√≥n

### Endpoints Disponibles

#### 1. Predicci√≥n Individual

```bash
POST /predict
```

**Request:**
```json
{
  "primary_type_freq": 0.123,
  "location_description_freq": 0.045,
  "beat_freq": 0.012,
  "ward_freq": 0.034,
  "community_area_freq": 0.028,
  "day_of_week_sin": 0.781,
  "x_coordinate_standardized": 1.234,
  "longitude_standardized": -0.567,
  "latitude_standardized": 0.890,
  "y_coordinate_standardized": -1.123,
  "distance_crime_to_police_station_standardized": 0.345
}
```

**Response:**
```json
{
  "prediction": true,
  "probability": 0.78,
  "model_version": "2",
  "timestamp": "2025-11-22T10:30:00Z"
}
```

#### 2. Predicci√≥n por Lote

```bash
POST /predict/batch
```

**Request:**
```json
{
  "instances": [
    { "primary_type_freq": 0.123, ... },
    { "primary_type_freq": 0.456, ... }
  ]
}
```

**Response:**
```json
{
  "predictions": [
    {
      "prediction": true,
      "probability": 0.78
    },
    {
      "prediction": false,
      "probability": 0.23
    }
  ],
  "model_version": "2",
  "timestamp": "2025-11-22T10:30:00Z"
}
```

#### 3. Informaci√≥n del Modelo

```bash
GET /model/info
```

**Response:**
```json
{
  "name": "chicago-crime-arrest-predictor",
  "version": "2",
  "stage": "Production",
  "description": "XGBoost classifier for arrest prediction",
  "metrics": {
    "accuracy": 0.85,
    "precision": 0.82,
    "recall": 0.79,
    "f1": 0.80,
    "roc_auc": 0.91
  }
}
```

### Ejemplos de Uso

**cURL:**
```bash
curl -X POST "http://localhost:8800/predict" \
  -H "Content-Type: application/json" \
  -d '{
    "primary_type_freq": 0.123,
    "location_description_freq": 0.045,
    "beat_freq": 0.012,
    "ward_freq": 0.034,
    "community_area_freq": 0.028,
    "day_of_week_sin": 0.781,
    "x_coordinate_standardized": 1.234,
    "longitude_standardized": -0.567,
    "latitude_standardized": 0.890,
    "y_coordinate_standardized": -1.123,
    "distance_crime_to_police_station_standardized": 0.345
  }'
```

**Python:**
```python
import requests

url = "http://localhost:8800/predict"
data = {
    "primary_type_freq": 0.123,
    "location_description_freq": 0.045,
    # ... resto de features
}

response = requests.post(url, json=data)
print(response.json())
```

**Documentaci√≥n Interactiva:**
- Swagger UI: http://localhost:8800/docs
- ReDoc: http://localhost:8800/redoc

---

## üìä Monitoreo y MLflow

### Acceso a MLflow UI

```bash
# Abrir en navegador
open http://localhost:5001

# O usar make command
make mlflow
```

### Experiments Creados

| Experiment | Descripci√≥n | Runs |
|------------|-------------|------|
| `Default` | Runs del pipeline ETL | `raw_data_*`, `split_*`, `balance_*`, `features_*`, `pipeline_summary_*` |
| `chicago-crime-arrest-prediction` | Experimentos de modelos | Tus experiments de entrenamiento |

### M√©tricas del Pipeline (ETL)

Cada ejecuci√≥n del pipeline crea 5 runs en MLflow:

**1. `raw_data_{date}`**
- M√©tricas: total_records, arrest_rate_pct, unique_districts, etc.
- Artifacts: `charts/raw_data_overview.png`

**2. `split_{date}`**
- M√©tricas: train_size, test_size, class distribution
- Artifacts: `charts/split_distribution.png`

**3. `balance_{date}`**
- M√©tricas: original_size, balanced_size, class_ratio improvement
- Artifacts: `charts/balance_comparison.png`

**4. `features_{date}`**
- M√©tricas: selected_features, dropped_features, feature_reduction_pct
- Artifacts: `charts/feature_importance.png`, `charts/correlation_heatmap.png`

**5. `pipeline_summary_{date}` ‚≠ê**
- M√©tricas: Todas las counts + retention percentages
- Artifacts: `charts/pipeline_flow.png` (overview completo del pipeline)

### Model Registry

**Estados del Modelo:**
- `None` - Reci√©n registrado
- `Staging` - En pruebas
- `Production` - Desplegado en API
- `Archived` - Versi√≥n antigua

**Transiciones:**
```python
from mlflow.tracking import MlflowClient

client = MlflowClient()

# Staging ‚Üí Production
client.transition_model_version_stage(
    name="chicago-crime-arrest-predictor",
    version="3",
    stage="Production"
)

# Archivar versi√≥n antigua
client.transition_model_version_stage(
    name="chicago-crime-arrest-predictor",
    version="2",
    stage="Archived"
)
```

---

## üõ†Ô∏è Comandos √ötiles

### Makefile Commands

```bash
make help      # Muestra todos los comandos disponibles
make up        # Inicia todos los servicios
make down      # Detiene todos los servicios
make restart   # Reinicia todos los servicios
make install   # Reconstruye contenedores con nuevas dependencias
make clean     # Detiene y elimina todo (‚ö†Ô∏è borra datos)
make logs      # Muestra logs de todos los servicios
make status    # Estado de todos los servicios
```

### Flujos de Trabajo Comunes

**Primera vez:**
```bash
make install && make up
```

**Agregar dependencias:**
```bash
# 1. Editar requirements.txt en dockerfiles/airflow/ o dockerfiles/fastapi/
# 2. Reconstruir
make install
```

**Reiniciar desde cero:**
```bash
make clean
make install && make up
```

## ETL Pipeline: Chicago Crime Data

El proyecto incluye un pipeline ETL completo para an√°lisis de cr√≠menes en Chicago:

### Arquitectura del Pipeline

**Task 1: setup_s3**
- Crea bucket MinIO si no existe
- Configura pol√≠tica de lifecycle (TTL de 60 d√≠as para datos temporales)

**Task 2: download_data**
- Descarga datos de cr√≠menes desde Socrata API (Chicago Data Portal)
- Descarga datos de estaciones policiales
- Primera ejecuci√≥n: descarga a√±o completo (~260k registros)
- Ejecuciones subsecuentes: descarga incremental mensual (~25k registros)
- Guarda en MinIO: `raw-data/crimes_YYYY-MM-DD.csv` y `raw-data/police_stations.csv`

**Task 3: enrich_data**
- Carga datos desde MinIO
- Calcula distancia a estaci√≥n policial m√°s cercana (GeoPandas spatial join)
- Crea features temporales:
  - Season (Winter/Spring/Summer/Fall)
  - Day of week (0-6)
  - Day time (Morning/Afternoon/Evening/Night)
- Guarda en MinIO: `raw-data/crimes_enriched_YYYY-MM-DD.csv`

**Tasks 4-8:** (Por implementar)
- `split_data` - Divisi√≥n train/test (80/20 estratificado)
- `process_outliers` - Manejo de outliers y transformaci√≥n logar√≠tmica
- `encode_data` - Encoding de variables categ√≥ricas
- `scale_data` - Escalado con StandardScaler
- `balance_data` - Balanceo con SMOTE + RandomUnderSampler
- `extract_features` - Selecci√≥n de features con Mutual Information

### Estructura de M√≥dulos

```
airflow/dags/
‚îú‚îÄ‚îÄ etl_process_taskflow.py       # DAG principal con TaskFlow API
‚îî‚îÄ‚îÄ etl_helpers/
    ‚îú‚îÄ‚îÄ __init__.py               # Package initialization
    ‚îú‚îÄ‚îÄ minio_utils.py            # Operaciones MinIO/S3
    ‚îú‚îÄ‚îÄ data_loader.py            # Descarga desde Socrata API
    ‚îî‚îÄ‚îÄ data_enrichment.py        # Enriquecimiento geoespacial y temporal
```

### Configuraci√≥n

**Variables de entorno requeridas (`.env`):**
```bash
SOCRATA_APP_TOKEN=tu_token_aqui  # Token de Socrata API
DATA_REPO_BUCKET_NAME=data        # Bucket MinIO para datos
```

**Dependencias principales:**
- `sodapy` - Cliente Socrata API
- `geopandas` - C√°lculos geoespaciales
- `shapely` - Geometr√≠as
- `pandas` - Manipulaci√≥n de datos

### Ejecuci√≥n

**Trigger manual:**
1. Abrir Airflow UI: `make airflow`
2. Localizar DAG: `etl_with_taskflow`
3. Click en "Play" para ejecutar

**Ejecuci√≥n autom√°tica:**
- Schedule: `@monthly` (primer d√≠a de cada mes)
- Primera ejecuci√≥n: descarga a√±o completo
- Subsecuentes: solo √∫ltimo mes

### Monitoreo

**Ver logs:**
```bash
# Levantar CLI
docker compose --profile all --profile debug up

# Ejemplos de uso
docker-compose run airflow-cli config list              # Ver configuraci√≥n
docker-compose run airflow-cli dags list                # Listar DAGs
docker-compose run airflow-cli tasks list etl_with_taskflow  # Listar tasks
docker-compose run airflow-cli dags trigger etl_with_taskflow  # Trigger manual
```

---

## ‚öôÔ∏è Configuraci√≥n Avanzada

### Variables de Entorno (.env)

```bash
# Airflow
AIRFLOW_UID=50000                    # UID del usuario (Linux/Mac)
AIRFLOW_IMAGE_NAME=extending_airflow:latest

# PostgreSQL
PG_USER=airflow
PG_PASSWORD=airflow
PG_DATABASE=airflow
PG_PORT=5432

# MinIO
MINIO_ACCESS_KEY=minio
MINIO_SECRET_ACCESS_KEY=minio123
MINIO_PORT=9000
MINIO_PORT_UI=9001

# MLflow
MLFLOW_PORT=5001
MLFLOW_BUCKET_NAME=mlflow

# Data
DATA_REPO_BUCKET_NAME=data
SOCRATA_APP_TOKEN=tu_token_aqui     # ‚ö†Ô∏è REQUERIDO

# FastAPI
FASTAPI_PORT=8800
```

### Conexi√≥n a MinIO desde Local

Para usar boto3, awscli, o pandas desde tu m√°quina local:

```bash
make airflow   # Ver DAG runs y logs
make minio     # Ver archivos en buckets
```

### Datos de Salida

**Ubicaci√≥n:** MinIO bucket `data/`

**Estructura:**
```
data/
‚îú‚îÄ‚îÄ 0-raw-data/
‚îÇ   ‚îú‚îÄ‚îÄ monthly-data/
‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ {YYYY-MM}/
‚îÇ   ‚îÇ       ‚îú‚îÄ‚îÄ crimes.csv              # Cr√≠menes descargados del mes
‚îÇ   ‚îÇ       ‚îî‚îÄ‚îÄ police_stations.csv     # Estaciones policiales
‚îÇ   ‚îî‚îÄ‚îÄ data/
‚îÇ       ‚îî‚îÄ‚îÄ crimes_12m_{YYYY-MM-DD}.csv # Ventana rolling 12 meses
‚îú‚îÄ‚îÄ 1-enriched-data/
‚îÇ   ‚îî‚îÄ‚îÄ crimes_enriched_{YYYY-MM-DD}.csv # Cr√≠menes enriquecidos
‚îî‚îÄ‚îÄ 2-processed-data/                    # (Pr√≥ximos pasos)
    ‚îú‚îÄ‚îÄ train_encoded.csv
    ‚îú‚îÄ‚îÄ test_encoded.csv
    ‚îî‚îÄ‚îÄ ...
```

## Apagar los servicios

Estos servicios ocupan cierta cantidad de memoria RAM y procesamiento, por lo que cuando no se est√°n utilizando, se recomienda detenerlos. Para hacerlo, ejecuta:

```bash
make down
```

**Eliminar todo (‚ö†Ô∏è borra datos):**
```bash
make clean
```

**Usando docker-compose directamente:**
```bash
# Solo detener
docker compose --profile all down

# Eliminar todo
docker compose down --rmi all --volumes
```

**Nota:** Si haces esto, perder√°s todo en los buckets y bases de datos.

## Aspectos espec√≠ficos de Airflow

### Variables de entorno
Airflow ofrece una amplia gama de opciones de configuraci√≥n. En el archivo `docker-compose.yaml`, dentro de `x-airflow-common`, se encuentran variables de entorno que pueden modificarse para ajustar la configuraci√≥n de Airflow. Pueden a√±adirse [otras variables](https://airflow.apache.org/docs/apache-airflow/stable/configurations-ref.html).

### Uso de ejecutores externos
Actualmente, para este caso, Airflow utiliza un ejecutor [celery](https://airflow.apache.org/docs/apache-airflow/stable/core-concepts/executor/celery.html), lo que significa que las tareas se ejecutan en otro contenedor. 

### Uso de la CLI de Airflow

Si necesitan depurar Apache Airflow, pueden utilizar la CLI de Apache Airflow de la siguiente manera:

```bash
docker compose --profile all --profile debug up
```

Una vez que el contenedor est√© en funcionamiento, pueden utilizar la CLI de Airflow de la siguiente manera, 
por ejemplo, para ver la configuraci√≥n:

```bash
docker-compose run airflow-cli config list      
```

Para obtener m√°s informaci√≥n sobre el comando, pueden consultar [aqui](https://airflow.apache.org/docs/apache-airflow/stable/cli-and-env-variables-ref.html).

### Variables y Conexiones

Si desean agregar variables para accederlas en los DAGs, pueden hacerlo en `secrets/variables.yaml`. Para obtener m√°s [informaci√≥n](https://airflow.apache.org/docs/apache-airflow/stable/core-concepts/variables.html), 
consulten la documentaci√≥n.

Si desean agregar conexiones en Airflow, pueden hacerlo en `secrets/connections.yaml`. Tambi√©n es posible agregarlas mediante la interfaz de usuario (UI), pero estas no persistir√°n si se borra todo. Por otro lado, cualquier conexi√≥n guardada en `secrets/connections.yaml` no aparecer√° en la UI, aunque eso no significa que no exista. Consulten la documentaci√≥n para obtener m√°s 
[informaci√≥n](https://airflow.apache.org/docs/apache-airflow/stable/authoring-and-scheduling/connections.html).

## Conexi√≥n con los buckets

Dado que no estamos utilizando Amazon S3, sino una implementaci√≥n local de los mismos mediante MinIO, es necesario modificar las variables de entorno para conectar con el servicio de MinIO. Las variables de entorno son las siguientes:

```bash
AWS_ACCESS_KEY_ID=minio   
AWS_SECRET_ACCESS_KEY=minio123 
AWS_ENDPOINT_URL_S3=http://localhost:90000
```

MLflow tambi√©n tiene una variable de entorno que afecta su conexi√≥n a los buckets:

```bash
MLFLOW_S3_ENDPOINT_URL=http://localhost:9000
```
Aseg√∫rate de establecer estas variables de entorno antes de ejecutar tu notebook o scripts en tu m√°quina o en cualquier otro lugar. Si est√°s utilizando un servidor externo a tu computadora de trabajo, reemplaza localhost por su direcci√≥n IP.

Al hacer esto, podr√°s utilizar `boto3`, `awswrangler`, etc., en Python con estos buckets, o `awscli` en la consola.

Si tienes acceso a AWS S3, ten mucho cuidado de no reemplazar tus credenciales de AWS. Si usas las variables de entorno, no tendr√°s problemas.

## Valkey

La base de datos Valkey es usada por Apache Airflow para su funcionamiento. Tal como est√° configurado ahora no esta expuesto el puerto para poder ser usado externamente. Se puede modificar el archivo `docker-compose.yaml` para habilitaro.

## Pull Request

Este repositorio est√° abierto para que realicen sus propios Pull Requests y as√≠ contribuir a mejorarlo. Si desean realizar alguna modificaci√≥n, **¬°son bienvenidos!** Tambi√©n se pueden crear nuevos entornos productivos para aumentar la variedad de implementaciones, idealmente en diferentes `branches`. Algunas ideas que se me ocurren que podr√≠an implementar son:

- Reemplazar Airflow y MLflow con [Metaflow](https://metaflow.org/) o [Kubeflow](https://www.kubeflow.org).
- Reemplazar MLflow con [Seldon-Core](https://github.com/SeldonIO/seldon-core).
- Agregar un servicio de tableros como, por ejemplo, [Grafana](https://grafana.com).
