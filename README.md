# Chicago Crime Arrest Prediction - MLOps Pipeline

PredicciÃ³n de arrestos en crÃ­menes reportados en la Ciudad de Chicago mediante un pipeline MLOps end-to-end.

## ğŸ‘¥ Autores

- Daniel Eduardo PeÃ±aranda Peralta
- Jorge AdriÃ¡n Alvarez
- MarÃ­a BelÃ©n Cattaneo
- NicolÃ¡s ValentÃ­n Ciarrapico
- Sabrina Daiana Pryszczuk

---

## âš™ï¸ Paso 1: ConfiguraciÃ³n Inicial

### Requisitos

- **Docker** y **Docker Compose** instalados
- **8GB RAM** mÃ­nimo disponible
- **10GB** espacio en disco

### Configurar Socrata API Token (Requerido)

El pipeline ETL descarga datos del **Chicago Data Portal** usando la API de Socrata. **Debes configurar un App Token antes de instalar**.

#### Obtener el Token

1. Ir a https://data.cityofchicago.org/
2. Crear una cuenta o iniciar sesiÃ³n (click en "Sign In" arriba a la derecha)
3. Una vez logueado, ir a tu perfil (click en tu nombre) â†’ **"Developer Settings"**
4. Click en **"Create New App Token"**
5. Completar el formulario:
   - **Application Name**: Nombre descriptivo (ej: "MLOps CEIA")
   - **Description**: DescripciÃ³n breve
   - **Website** (opcional): Puede dejarse vacÃ­o
6. Click en **"Save"** y copiar el **App Token** generado

#### Configurar el Token en el Proyecto

Abrir el archivo `Makefile` y reemplazar el token en la **lÃ­nea 4**:

```makefile
SOCRATA_TOKEN ?= tu_token_generado_aqui
```

> âš ï¸ **Importante**: Sin el token configurado, el pipeline ETL fallarÃ¡ o serÃ¡ extremadamente lento.

### Siguiente paso

Una vez configurado el token, continÃºa con la instalaciÃ³n segÃºn tu sistema operativo:

- **macOS / Linux** â†’ [Ir a instalaciÃ³n](#-paso-2a-instalaciÃ³n-macos--linux)
- **Windows** â†’ [Ir a instalaciÃ³n](#-paso-2b-instalaciÃ³n-windows-wsl2)

---

## ğŸ“¦ Paso 2a: InstalaciÃ³n (macOS / Linux)

```bash
cd MLOPS-main
make install
```

Este comando automÃ¡ticamente:
- Crea directorios necesarios (`airflow/logs`, etc.)
- Configura permisos
- Crea archivo `.env` con configuraciÃ³n por defecto
- Construye todos los contenedores Docker
- Levanta todos los servicios

#### Verificar instalaciÃ³n

```bash
make status
```

Todos los servicios deben mostrar `(healthy)`. Esperar ~2 minutos si algunos servicios aÃºn estÃ¡n iniciando.

#### DesinstalaciÃ³n

```bash
# Limpieza completa (elimina datos, logs, .env)
make uninstall

# Solo detener servicios (mantiene datos)
make down
```

**Siguiente paso** â†’ [Ir a EjecuciÃ³n](#-paso-3-ejecuciÃ³n)

---

## ğŸ“¦ Paso 2b: InstalaciÃ³n (Windows WSL2)

Windows requiere **WSL2** (Windows Subsystem for Linux) ya que el proyecto usa comandos Unix.

### 1. Instalar WSL2

```powershell
# En PowerShell como Administrador
wsl --install
```

Reiniciar el equipo despuÃ©s de la instalaciÃ³n.

### 2. Instalar Docker Desktop

1. Descargar [Docker Desktop](https://www.docker.com/products/docker-desktop/)
2. Durante la instalaciÃ³n, habilitar **WSL2 backend**
3. En Docker Desktop â†’ Settings â†’ Resources â†’ WSL Integration â†’ Habilitar para tu distro

### 3. Instalar el proyecto

```bash
# Abrir terminal WSL2 (Ubuntu)
wsl

# Navegar al proyecto
cd /mnt/c/Users/TuUsuario/MLOPS-main

# Instalar
make install
```

### 4. Verificar

```bash
make status
```

Todos los servicios deben mostrar `(healthy)`.

### DesinstalaciÃ³n

```bash
wsl
make uninstall
```

**Siguiente paso** â†’ [Ir a EjecuciÃ³n](#-paso-3-ejecuciÃ³n)

---

## ğŸ”„ Paso 3: EjecuciÃ³n

### Servicios disponibles

| Servicio | URL | Credenciales |
|----------|-----|--------------|
| Airflow | http://localhost:8080 | `airflow` / `airflow` |
| MLflow | http://localhost:5001 | â€” |
| MinIO | http://localhost:9001 | `minio` / `minio123` |
| API | http://localhost:8800/docs | â€” |

### Comandos (ejecutar en orden)

```bash
make airflow    # 1. Abrir Airflow â†’ ejecutar DAG 'etl_with_taskflow' â†’ esperar ~15min
make train      # 2. Entrenar modelo XGBoost
make champion   # 3. Asignar como champion
make reload     # 4. Cargar modelo en API
make api        # 5. Abrir documentaciÃ³n API
```

<details>
<summary><strong>Detalles de cada paso (click para expandir)</strong></summary>

#### 1. Ejecutar ETL Pipeline

En la UI de Airflow (http://localhost:8080):
- Buscar DAG: `etl_with_taskflow`
- Activar el toggle (si estÃ¡ pausado)
- Click â–¶ï¸ para ejecutar
- Esperar ~10-15 minutos hasta que todas las tareas estÃ©n en verde âœ…

#### 2. Entrenar modelo

El comando `make train` entrena un modelo XGBoost y lo registra en MLflow.

#### 3. Asignar modelo como Champion

El comando `make champion` asigna el alias `champion` a la Ãºltima versiÃ³n del modelo.

#### 4. Cargar modelo en API

El comando `make reload` carga el modelo champion en la API.

#### 5. Usar la API

Ejemplo de predicciÃ³n con cURL:

```bash
curl -X POST "http://localhost:8800/predict" \
  -H "Content-Type: application/json" \
  -d '{
    "iucr_freq": 0.03,
    "primary_type_freq": 0.1,
    "location_description_freq": 0.05,
    "day_of_week_sin": 0.5,
    "x_coordinate_standardized": 0.12,
    "y_coordinate_standardized": -0.34,
    "distance_crime_to_police_station_standardized": 0.56
  }'
```

</details>

---

## ğŸ“‹ Comandos Disponibles

```bash
make help         # Ver todos los comandos

# InstalaciÃ³n
make install      # InstalaciÃ³n completa
make uninstall    # DesinstalaciÃ³n completa
make setup        # Solo crear directorios y .env

# Servicios
make up           # Iniciar servicios
make down         # Detener servicios
make restart      # Reiniciar servicios
make status       # Ver estado
make logs         # Ver logs en tiempo real
make clean        # Eliminar contenedores y volÃºmenes

# ML Pipeline
make train        # Entrenar modelo XGBoost
make champion     # Asignar modelo como champion
make reload       # Recargar modelo en API

# Abrir interfaces
make airflow      # http://localhost:8080
make mlflow       # http://localhost:5001
make minio        # http://localhost:9001
make api          # http://localhost:8800/docs
```

---

## ğŸ—ï¸ Arquitectura

<details>
<summary><strong>Click para expandir</strong></summary>

### Estructura del Proyecto

```
MLOPS-main/
â”œâ”€â”€ src/                          # CÃ³digo fuente
â”‚   â”œâ”€â”€ api/                      # FastAPI
â”‚   â”‚   â””â”€â”€ app.py
â”‚   â””â”€â”€ training/                 # Scripts ML
â”‚       â”œâ”€â”€ train_xgboost.py
â”‚       â”œâ”€â”€ champion_challenger.py
â”‚       â””â”€â”€ predictor.py
â”œâ”€â”€ airflow/                      # Apache Airflow
â”‚   â”œâ”€â”€ dags/
â”‚   â”‚   â”œâ”€â”€ etl_process_taskflow.py
â”‚   â”‚   â””â”€â”€ etl_helpers/
â”‚   â””â”€â”€ secrets/
â”œâ”€â”€ docker/                       # Dockerfiles
â”‚   â”œâ”€â”€ airflow/
â”‚   â”œâ”€â”€ fastapi/
â”‚   â”œâ”€â”€ mlflow/
â”‚   â”œâ”€â”€ postgres/
â”‚   â””â”€â”€ trainer/
â”œâ”€â”€ tests/
â”œâ”€â”€ docs/
â”œâ”€â”€ docker-compose.yaml
â”œâ”€â”€ Makefile
â””â”€â”€ README.md
```

### Flujo MLOps

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”     â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”     â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”     â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  ETL        â”‚ â”€â”€â–¶ â”‚  Training   â”‚ â”€â”€â–¶ â”‚  Registry   â”‚ â”€â”€â–¶ â”‚  Serving    â”‚
â”‚  (Airflow)  â”‚     â”‚  (XGBoost)  â”‚     â”‚  (MLflow)   â”‚     â”‚  (FastAPI)  â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜     â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜     â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜     â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
     â”‚                    â”‚                   â”‚                   â”‚
     â–¼                    â–¼                   â–¼                   â–¼
  MinIO               MLflow              Model              /predict
  s3://data          Tracking            Registry           Endpoint
```

</details>

---

## ğŸŒ API Reference

<details>
<summary><strong>Click para expandir</strong></summary>

### Endpoints

| MÃ©todo | Endpoint | DescripciÃ³n |
|--------|----------|-------------|
| GET | `/health` | Health check |
| POST | `/predict` | PredicciÃ³n individual |
| POST | `/predict/batch` | PredicciÃ³n por lote (max 1000) |
| GET | `/model/info` | Info del modelo |
| POST | `/model/reload` | Recargar modelo |

### Input Features (7 total)

| Feature | DescripciÃ³n |
|---------|-------------|
| `iucr_freq` | Frequency encoding del cÃ³digo IUCR |
| `primary_type_freq` | Frequency encoding del tipo de crimen |
| `location_description_freq` | Frequency encoding de la ubicaciÃ³n |
| `day_of_week_sin` | Encoding cÃ­clico del dÃ­a de semana |
| `x_coordinate_standardized` | Coordenada X estandarizada |
| `y_coordinate_standardized` | Coordenada Y estandarizada |
| `distance_crime_to_police_station_standardized` | Distancia a comisarÃ­a (estandarizada) |

### Ejemplo Response

```json
{
  "prediction": true,
  "probability": 0.78,
  "model_version": "2",
  "timestamp": "2025-12-14T15:30:00Z"
}
```

</details>

---

## ğŸ”§ ETL Pipeline

<details>
<summary><strong>Click para expandir</strong></summary>

### Etapas

1. **Setup S3** - Crea buckets en MinIO
2. **Download Data** - Descarga datos de Chicago Data Portal
3. **Enrich Data** - Agrega features geoespaciales y temporales
4. **Split Data** - DivisiÃ³n train/test (80/20)
5. **Process Outliers** - Manejo de outliers
6. **Encode Data** - Encoding de categÃ³ricas
7. **Scale Data** - EstandarizaciÃ³n
8. **Balance Data** - SMOTE + Undersampling
9. **Extract Features** - SelecciÃ³n con Mutual Information
10. **Pipeline Summary** - MÃ©tricas consolidadas

### Datos de salida

```
s3://data/ml-ready-data/
â”œâ”€â”€ train_{date}.csv    # ~173k registros Ã— 7 features
â””â”€â”€ test_{date}.csv     # ~46k registros Ã— 7 features
```

</details>

---

## ğŸ†˜ Troubleshooting

<details>
<summary><strong>Click para expandir</strong></summary>

### Servicios no inician

```bash
make logs      # Ver logs
make restart   # Reiniciar
```

### Permisos en airflow/logs (Linux/Mac)

```bash
sudo chmod 777 airflow/logs
make restart
```

### Puerto 5000 ocupado (macOS)

MLflow usa puerto 5001 por defecto para evitar conflicto con AirPlay.

### ETL falla en download_data

Verificar que el Socrata Token estÃ¡ configurado correctamente en el `Makefile`.

### ETL falla en balance_data

Verificar que el ETL completo se ejecutÃ³. Si hay errores previos, los datos pueden tener NaN.

### Modelo no carga en API

```bash
make champion  # Verificar que existe el alias
make reload    # Recargar
```

### Windows: make command not found

Usar WSL2:
```bash
wsl
cd /mnt/c/path/to/MLOPS-main
make install
```

</details>

---

## ğŸ“š DocumentaciÃ³n Adicional

- [Consigna del Proyecto](docs/CONSIGNAS.md)
- [API Documentation](http://localhost:8800/docs) (requiere servicios activos)
- [MLflow UI](http://localhost:5001) (requiere servicios activos)

---

## ğŸ“„ Licencia

MIT License - Ver archivo [LICENSE](LICENSE)
